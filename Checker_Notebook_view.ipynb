{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/python2\n",
    "import pefile\n",
    "import os\n",
    "import array\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "import sys\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(data):\n",
    "    if len(data) == 0:\n",
    "        return 0.0\n",
    "    occurences = array.array('L', [0] * 256)\n",
    "    for x in data:\n",
    "        occurences[x if isinstance(x, int) else ord(x)] += 1\n",
    "\n",
    "    entropy = 0\n",
    "    for x in occurences:\n",
    "        if x:\n",
    "            p_x = float(x) / len(data)\n",
    "            entropy -= p_x * math.log(p_x, 2)\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resources(pe):\n",
    "    \"\"\"Extract resources :\n",
    "    [entropy, size]\"\"\"\n",
    "    resources = []\n",
    "    if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):\n",
    "        try:\n",
    "            for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:\n",
    "                if hasattr(resource_type, 'directory'):\n",
    "                    for resource_id in resource_type.directory.entries:\n",
    "                        if hasattr(resource_id, 'directory'):\n",
    "                            for resource_lang in resource_id.directory.entries:\n",
    "                                data = pe.get_data(resource_lang.data.struct.OffsetToData,\n",
    "                                                   resource_lang.data.struct.Size)\n",
    "                                size = resource_lang.data.struct.Size\n",
    "                                entropy = get_entropy(data)\n",
    "\n",
    "                                resources.append([entropy, size])\n",
    "        except Exception as e:\n",
    "            return resources\n",
    "    return resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_version_info(pe):\n",
    "    \"\"\"Return version infos\"\"\"\n",
    "    res = {}\n",
    "    for fileinfo in pe.FileInfo:\n",
    "        if fileinfo.Key == 'StringFileInfo':\n",
    "            for st in fileinfo.StringTable:\n",
    "                for entry in st.entries.items():\n",
    "                    res[entry[0]] = entry[1]\n",
    "        if fileinfo.Key == 'VarFileInfo':\n",
    "            for var in fileinfo.Var:\n",
    "                res[var.entry.items()[0][0]] = var.entry.items()[0][1]\n",
    "    if hasattr(pe, 'VS_FIXEDFILEINFO'):\n",
    "        res['flags'] = pe.VS_FIXEDFILEINFO.FileFlags\n",
    "        res['os'] = pe.VS_FIXEDFILEINFO.FileOS\n",
    "        res['type'] = pe.VS_FIXEDFILEINFO.FileType\n",
    "        res['file_version'] = pe.VS_FIXEDFILEINFO.FileVersionLS\n",
    "        res['product_version'] = pe.VS_FIXEDFILEINFO.ProductVersionLS\n",
    "        res['signature'] = pe.VS_FIXEDFILEINFO.Signature\n",
    "        res['struct_version'] = pe.VS_FIXEDFILEINFO.StrucVersion\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_infos(fpath):\n",
    "    res = {}\n",
    "    pe = pefile.PE(fpath)\n",
    "    res['Machine'] = pe.FILE_HEADER.Machine\n",
    "    res['SizeOfOptionalHeader'] = pe.FILE_HEADER.SizeOfOptionalHeader\n",
    "    res['Characteristics'] = pe.FILE_HEADER.Characteristics\n",
    "    res['MajorLinkerVersion'] = pe.OPTIONAL_HEADER.MajorLinkerVersion\n",
    "    res['MinorLinkerVersion'] = pe.OPTIONAL_HEADER.MinorLinkerVersion\n",
    "    res['SizeOfCode'] = pe.OPTIONAL_HEADER.SizeOfCode\n",
    "    res['SizeOfInitializedData'] = pe.OPTIONAL_HEADER.SizeOfInitializedData\n",
    "    res['SizeOfUninitializedData'] = pe.OPTIONAL_HEADER.SizeOfUninitializedData\n",
    "    res['AddressOfEntryPoint'] = pe.OPTIONAL_HEADER.AddressOfEntryPoint\n",
    "    res['BaseOfCode'] = pe.OPTIONAL_HEADER.BaseOfCode\n",
    "    try:\n",
    "        res['BaseOfData'] = pe.OPTIONAL_HEADER.BaseOfData\n",
    "    except AttributeError:\n",
    "        res['BaseOfData'] = 0\n",
    "    res['ImageBase'] = pe.OPTIONAL_HEADER.ImageBase\n",
    "    res['SectionAlignment'] = pe.OPTIONAL_HEADER.SectionAlignment\n",
    "    res['FileAlignment'] = pe.OPTIONAL_HEADER.FileAlignment\n",
    "    res['MajorOperatingSystemVersion'] = pe.OPTIONAL_HEADER.MajorOperatingSystemVersion\n",
    "    res['MinorOperatingSystemVersion'] = pe.OPTIONAL_HEADER.MinorOperatingSystemVersion\n",
    "    res['MajorImageVersion'] = pe.OPTIONAL_HEADER.MajorImageVersion\n",
    "    res['MinorImageVersion'] = pe.OPTIONAL_HEADER.MinorImageVersion\n",
    "    res['MajorSubsystemVersion'] = pe.OPTIONAL_HEADER.MajorSubsystemVersion\n",
    "    res['MinorSubsystemVersion'] = pe.OPTIONAL_HEADER.MinorSubsystemVersion\n",
    "    res['SizeOfImage'] = pe.OPTIONAL_HEADER.SizeOfImage\n",
    "    res['SizeOfHeaders'] = pe.OPTIONAL_HEADER.SizeOfHeaders\n",
    "    res['CheckSum'] = pe.OPTIONAL_HEADER.CheckSum\n",
    "    res['Subsystem'] = pe.OPTIONAL_HEADER.Subsystem\n",
    "    res['DllCharacteristics'] = pe.OPTIONAL_HEADER.DllCharacteristics\n",
    "    res['SizeOfStackReserve'] = pe.OPTIONAL_HEADER.SizeOfStackReserve\n",
    "    res['SizeOfStackCommit'] = pe.OPTIONAL_HEADER.SizeOfStackCommit\n",
    "    res['SizeOfHeapReserve'] = pe.OPTIONAL_HEADER.SizeOfHeapReserve\n",
    "    res['SizeOfHeapCommit'] = pe.OPTIONAL_HEADER.SizeOfHeapCommit\n",
    "    res['LoaderFlags'] = pe.OPTIONAL_HEADER.LoaderFlags\n",
    "    res['NumberOfRvaAndSizes'] = pe.OPTIONAL_HEADER.NumberOfRvaAndSizes\n",
    "\n",
    "    # Sections\n",
    "    res['SectionsNb'] = len(pe.sections)\n",
    "    entropy = map(lambda x: x.get_entropy(), pe.sections)\n",
    "    res['SectionsMeanEntropy'] = sum(entropy) / float(len(entropy))\n",
    "    res['SectionsMinEntropy'] = min(entropy)\n",
    "    res['SectionsMaxEntropy'] = max(entropy)\n",
    "    raw_sizes = map(lambda x: x.SizeOfRawData, pe.sections)\n",
    "    res['SectionsMeanRawsize'] = sum(raw_sizes) / float(len(raw_sizes))\n",
    "    res['SectionsMinRawsize'] = min(raw_sizes)\n",
    "    res['SectionsMaxRawsize'] = max(raw_sizes)\n",
    "    virtual_sizes = map(lambda x: x.Misc_VirtualSize, pe.sections)\n",
    "    res['SectionsMeanVirtualsize'] = sum(virtual_sizes) / float(len(virtual_sizes))\n",
    "    res['SectionsMinVirtualsize'] = min(virtual_sizes)\n",
    "    res['SectionMaxVirtualsize'] = max(virtual_sizes)\n",
    "\n",
    "    # Imports\n",
    "    try:\n",
    "        res['ImportsNbDLL'] = len(pe.DIRECTORY_ENTRY_IMPORT)\n",
    "        imports = sum([x.imports for x in pe.DIRECTORY_ENTRY_IMPORT], [])\n",
    "        res['ImportsNb'] = len(imports)\n",
    "        res['ImportsNbOrdinal'] = len(filter(lambda x: x.name is None, imports))\n",
    "    except AttributeError:\n",
    "        res['ImportsNbDLL'] = 0\n",
    "        res['ImportsNb'] = 0\n",
    "        res['ImportsNbOrdinal'] = 0\n",
    "\n",
    "    # Exports\n",
    "    try:\n",
    "        res['ExportNb'] = len(pe.DIRECTORY_ENTRY_EXPORT.symbols)\n",
    "    except AttributeError:\n",
    "        # No export\n",
    "        res['ExportNb'] = 0\n",
    "    # Resources\n",
    "    resources = get_resources(pe)\n",
    "    res['ResourcesNb'] = len(resources)\n",
    "    if len(resources) > 0:\n",
    "        entropy = map(lambda x: x[0], resources)\n",
    "        res['ResourcesMeanEntropy'] = sum(entropy) / float(len(entropy))\n",
    "        res['ResourcesMinEntropy'] = min(entropy)\n",
    "        res['ResourcesMaxEntropy'] = max(entropy)\n",
    "        sizes = map(lambda x: x[1], resources)\n",
    "        res['ResourcesMeanSize'] = sum(sizes) / float(len(sizes))\n",
    "        res['ResourcesMinSize'] = min(sizes)\n",
    "        res['ResourcesMaxSize'] = max(sizes)\n",
    "    else:\n",
    "        res['ResourcesNb'] = 0\n",
    "        res['ResourcesMeanEntropy'] = 0\n",
    "        res['ResourcesMinEntropy'] = 0\n",
    "        res['ResourcesMaxEntropy'] = 0\n",
    "        res['ResourcesMeanSize'] = 0\n",
    "        res['ResourcesMinSize'] = 0\n",
    "        res['ResourcesMaxSize'] = 0\n",
    "\n",
    "    # Load configuration size\n",
    "    try:\n",
    "        res['LoadConfigurationSize'] = pe.DIRECTORY_ENTRY_LOAD_CONFIG.struct.Size\n",
    "    except AttributeError:\n",
    "        res['LoadConfigurationSize'] = 0\n",
    "\n",
    "    # Version configuration size\n",
    "    try:\n",
    "        version_infos = get_version_info(pe)\n",
    "        res['VersionInformationSize'] = len(version_infos.keys())\n",
    "    except AttributeError:\n",
    "        res['VersionInformationSize'] = 0\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] FILE\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Detect malicious files')\n",
    "    parser.add_argument('FILE', help='File to be tested')\n",
    "    args = parser.parse_args()\n",
    "    # Load classifier\n",
    "    clf = joblib.load(os.path.join(\n",
    "        os.path.dirname(os.path.realpath(__file__)),\n",
    "        'classifier/classifier.pkl'\n",
    "    ))\n",
    "    features = pickle.loads(open(os.path.join(\n",
    "        os.path.dirname(os.path.realpath(__file__)),\n",
    "        'classifier/features.pkl'),\n",
    "        'r').read()\n",
    "                            )\n",
    "\n",
    "    #arg.FILE will pass path for EXE file   \n",
    "    data = extract_infos(args.FILE)  \n",
    "\n",
    "    pe_features = map(lambda x: data[x], features)\n",
    "\n",
    "    res = clf.predict([pe_features])[0]\n",
    "    print('The file %s is %s' % (os.path.basename(sys.argv[1]),['malicious', 'legitimate'][res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U have to pass an argument ex: exe file\n"
     ]
    }
   ],
   "source": [
    "print(\"U have to pass an argument ex: exe file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
